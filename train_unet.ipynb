{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import load_data\n",
    "from segmentation_models_pytorch import Unet\n",
    "import os\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Argument parsing\n",
    "# parser = argparse.ArgumentParser(description=\"Train U-Net model from scratch\")\n",
    "# parser.add_argument(\"--lr\", type=float, default=0.001, help=\"Learning rate for optimizer\")\n",
    "# parser.add_argument(\"--batch_size\", type=int, default=16, help=\"Batch size for training\")\n",
    "# parser.add_argument(\"--epochs\", type=int, default=10, help=\"Number of training epochs\")\n",
    "# args = parser.parse_args()\n",
    "\n",
    "lr = 0.0001\n",
    "batch_size = 32\n",
    "epochs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03cfcd7d83f1499ba3940d039964f525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/1508 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c3ad137bfaf43eda720f34864b5f36c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/1508 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading filtered AIA 171 (2014)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7923a3975a3e4aa89b816821923fc693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/171 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading filtered AIA 171 (2016)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c13179f17c604acea35c1c99a4d2ab07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading filtered AIA 193 (2014)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a8012b8783b46fbb882ede3f0529f76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/171 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading filtered AIA 193 (2016)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba7e91c0e0d1491d89836ef4951a504f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset from disk:   0%|          | 0/174 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "save_model_dir = \"./saved_models_from_scratch\"\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "\n",
    "path_171 = \"../sho/ceph/20241008_cwan1/ceph/datasets/AIA/171\"\n",
    "path_193 = \"../sho/ceph/20241008_cwan1/ceph/datasets/AIA/193\"\n",
    "save_dir = \"../hzhu2/ceph/filtered_common_timestamps\"\n",
    "\n",
    "# Load train and test datasets\n",
    "train_loader, test_loader = load_data.load_filtered_data(path_171, path_193, batch_size=batch_size, save_dir=save_dir, num_proc=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model...\n",
      "Model initialized.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize U-Net model without pretrained weights\n",
    "print(\"Initializing model...\")\n",
    "model = Unet(\n",
    "    encoder_name=\"resnet18\",  # No encoder is used, so the model will be trained from scratch\n",
    "    encoder_weights=None,\n",
    "    in_channels=1,\n",
    "    classes=1\n",
    ").to(device)\n",
    "print(\"Model initialized.\")\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.L1Loss()  # MAE\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# adamw\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MAE calculation function\n",
    "def calculate_mae(gt, pred):\n",
    "    \"\"\"Calculates Mean Absolute Error.\"\"\"\n",
    "    return np.mean(np.abs(gt - pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training loop\n",
    "def train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs=10):\n",
    "    start_time = time.time()\n",
    "    print(\"Training started...\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "        epoch_duration = time.time() - epoch_start_time\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {avg_train_loss:.4f}\")\n",
    "        print(f\"Epoch duration: {epoch_duration:.2f} seconds\")\n",
    "\n",
    "        # Save model checkpoint\n",
    "        model_path = os.path.join(save_model_dir, f\"unet_epoch_{epoch+1}.pth\")\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(f\"Model saved at {model_path}\")\n",
    "\n",
    "        # Validate the model\n",
    "        avg_val_loss, model_mae = validate_model(model, test_loader, criterion)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] Validation Loss: {avg_val_loss:.4f}, Model MAE: {model_mae:.4f}\")\n",
    "\n",
    "    total_training_time = time.time() - start_time\n",
    "    print(f\"Training completed in {total_training_time / 60:.2f} minutes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def validate_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            all_preds.append(outputs.cpu().numpy().flatten())\n",
    "            all_targets.append(targets.cpu().numpy().flatten())\n",
    "\n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "    model_mae = calculate_mae(np.concatenate(all_targets), np.concatenate(all_preds))\n",
    "    return avg_val_loss, model_mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scatter plot function using plt.hexbin\n",
    "def plot_hexbin(gt, predictions, baseline_predictions, model_mae, baseline_mae, save_path=\"./plot_output\"):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.hexbin(gt, predictions, gridsize=50, cmap='Blues', mincnt=1, alpha=0.7)\n",
    "    plt.colorbar(label='Counts')\n",
    "    \n",
    "    plt.hexbin(gt, baseline_predictions, gridsize=50, cmap='Oranges', mincnt=1, alpha=0.5)\n",
    "    plt.xlabel('Ground Truth (AIA 171)')\n",
    "    plt.ylabel('Predictions (AIA 171)')\n",
    "    plt.title(\"Model vs Baseline\")\n",
    "    \n",
    "    plt.text(0.05, 0.9, f\"Model MAE: {model_mae:.4f}\", transform=plt.gca().transAxes, fontsize=12, color=\"blue\")\n",
    "    plt.text(0.05, 0.85, f\"Baseline MAE: {baseline_mae:.4f}\", transform=plt.gca().transAxes, fontsize=12, color=\"orange\")\n",
    "    \n",
    "    plot_filename = os.path.join(save_path, \"hexbin_plot.png\")\n",
    "    plt.savefig(plot_filename)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Baseline model calculation\n",
    "def baseline_model(train_loader, test_loader):\n",
    "    print(\"Calculating baseline model...\")\n",
    "\n",
    "    total_sum, total_count = 0.0, 0\n",
    "    for _, targets in train_loader:\n",
    "        total_sum += targets.sum().item()\n",
    "        total_count += targets.numel()\n",
    "    \n",
    "    avg_value = total_sum / total_count\n",
    "    print(f\"Average target value (baseline prediction): {avg_value:.4f}\")\n",
    "\n",
    "    all_baseline_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    for _, targets in test_loader:\n",
    "        baseline_pred = np.full_like(targets.cpu().numpy(), avg_value)\n",
    "        all_baseline_preds.append(baseline_pred.flatten())\n",
    "        all_targets.append(targets.cpu().numpy().flatten())\n",
    "\n",
    "    baseline_mae = calculate_mae(np.concatenate(all_targets), np.concatenate(all_baseline_preds))\n",
    "    return np.concatenate(all_targets), np.concatenate(all_baseline_preds), baseline_mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [0/2530], Loss: 532.4308\n",
      "Epoch [1/10], Step [10/2530], Loss: 538.0287\n",
      "Epoch [1/10], Step [20/2530], Loss: 524.0112\n",
      "Epoch [1/10], Step [30/2530], Loss: 539.7396\n",
      "Epoch [1/10], Step [40/2530], Loss: 530.7170\n",
      "Epoch [1/10], Step [50/2530], Loss: 531.2313\n",
      "Epoch [1/10], Step [60/2530], Loss: 534.5693\n",
      "Epoch [1/10], Step [70/2530], Loss: 527.5385\n",
      "Epoch [1/10], Step [80/2530], Loss: 543.3658\n",
      "Epoch [1/10], Step [90/2530], Loss: 545.5748\n",
      "Epoch [1/10], Step [100/2530], Loss: 524.9426\n",
      "Epoch [1/10], Step [110/2530], Loss: 535.7201\n",
      "Epoch [1/10], Step [120/2530], Loss: 544.7258\n",
      "Epoch [1/10], Step [130/2530], Loss: 534.4856\n",
      "Epoch [1/10], Step [140/2530], Loss: 516.0465\n",
      "Epoch [1/10], Step [150/2530], Loss: 532.2822\n",
      "Epoch [1/10], Step [160/2530], Loss: 535.0564\n",
      "Epoch [1/10], Step [170/2530], Loss: 543.2672\n",
      "Epoch [1/10], Step [180/2530], Loss: 535.9422\n",
      "Epoch [1/10], Step [190/2530], Loss: 528.1100\n",
      "Epoch [1/10], Step [200/2530], Loss: 532.8813\n",
      "Epoch [1/10], Step [210/2530], Loss: 535.6449\n",
      "Epoch [1/10], Step [220/2530], Loss: 528.4342\n",
      "Epoch [1/10], Step [230/2530], Loss: 543.8950\n",
      "Epoch [1/10], Step [240/2530], Loss: 526.7764\n",
      "Epoch [1/10], Step [250/2530], Loss: 526.4161\n",
      "Epoch [1/10], Step [260/2530], Loss: 533.0253\n",
      "Epoch [1/10], Step [270/2530], Loss: 522.1986\n",
      "Epoch [1/10], Step [280/2530], Loss: 525.2921\n",
      "Epoch [1/10], Step [290/2530], Loss: 525.2192\n",
      "Epoch [1/10], Step [300/2530], Loss: 528.9927\n",
      "Epoch [1/10], Step [310/2530], Loss: 535.8779\n",
      "Epoch [1/10], Step [320/2530], Loss: 534.7950\n",
      "Epoch [1/10], Step [330/2530], Loss: 522.9178\n",
      "Epoch [1/10], Step [340/2530], Loss: 527.1879\n",
      "Epoch [1/10], Step [350/2530], Loss: 536.8722\n",
      "Epoch [1/10], Step [360/2530], Loss: 527.3341\n",
      "Epoch [1/10], Step [370/2530], Loss: 543.5557\n",
      "Epoch [1/10], Step [380/2530], Loss: 528.5291\n",
      "Epoch [1/10], Step [390/2530], Loss: 532.1232\n",
      "Epoch [1/10], Step [400/2530], Loss: 525.0837\n",
      "Epoch [1/10], Step [410/2530], Loss: 527.9739\n",
      "Epoch [1/10], Step [420/2530], Loss: 536.2560\n",
      "Epoch [1/10], Step [430/2530], Loss: 538.2155\n",
      "Epoch [1/10], Step [440/2530], Loss: 531.8771\n",
      "Epoch [1/10], Step [450/2530], Loss: 524.7661\n",
      "Epoch [1/10], Step [460/2530], Loss: 531.9399\n",
      "Epoch [1/10], Step [470/2530], Loss: 528.2167\n",
      "Epoch [1/10], Step [480/2530], Loss: 530.5963\n",
      "Epoch [1/10], Step [490/2530], Loss: 537.7887\n",
      "Epoch [1/10], Step [500/2530], Loss: 523.1305\n",
      "Epoch [1/10], Step [510/2530], Loss: 521.3470\n",
      "Epoch [1/10], Step [520/2530], Loss: 527.1155\n",
      "Epoch [1/10], Step [530/2530], Loss: 536.6858\n",
      "Epoch [1/10], Step [540/2530], Loss: 532.4570\n",
      "Epoch [1/10], Step [550/2530], Loss: 532.2668\n",
      "Epoch [1/10], Step [560/2530], Loss: 532.9421\n",
      "Epoch [1/10], Step [570/2530], Loss: 531.0858\n",
      "Epoch [1/10], Step [580/2530], Loss: 542.6728\n",
      "Epoch [1/10], Step [590/2530], Loss: 516.8919\n",
      "Epoch [1/10], Step [600/2530], Loss: 536.8418\n",
      "Epoch [1/10], Step [610/2530], Loss: 537.4043\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train and Evaluate\n",
    "train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get results from the trained model and baseline\n",
    "gt, model_preds, model_mae = validate_model(model, test_loader, criterion)\n",
    "_, baseline_preds, baseline_mae = baseline_model(train_loader, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot comparison of baseline vs trained model\n",
    "plot_hexbin(gt, model_preds, baseline_preds, model_mae, baseline_mae)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "solar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
